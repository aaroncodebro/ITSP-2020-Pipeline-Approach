{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Math-Symbol-Recog.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGrl6kd2an0g",
        "colab_type": "code",
        "outputId": "f46f3a14-84c1-4de3-ee3a-08ef23d590af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5qz2NSHawjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/My Drive/extracted_images.zip') as z:\n",
        "  z.extractall('/content/drive/My Drive/extracted_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WqSE062zDbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ddfde3c-d055-46da-d04a-448b418901d5"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1eoBRmVz1zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from skimage.io import imread, imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "random_seed = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ52KV7O0Iwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sym_to_int_dict = {\n",
        "    '0': 0,\n",
        "    '1': 1,\n",
        "    '2': 2,\n",
        "    '3': 3,\n",
        "    '4': 4,\n",
        "    '5': 5,\n",
        "    '6': 6,\n",
        "    '7': 7,\n",
        "    '8': 8,\n",
        "    '9': 9,\n",
        "    'cos': 10,\n",
        "    'div': 11,\n",
        "    'infty': 12,\n",
        "    'int': 13,\n",
        "    'log': 14,\n",
        "    'pi': 15,\n",
        "    'sin': 16,\n",
        "    'sqrt': 17,\n",
        "    'tan': 18,\n",
        "    'x': 19,\n",
        "    'y': 20,\n",
        "    '-': 21,\n",
        "    '(': 22,\n",
        "    ')': 23,\n",
        "    '+': 24\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaM0q1vw7QZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d2e15aa3-e572-479b-f24b-363a938a7ec7"
      },
      "source": [
        "key_list = list(sym_to_int_dict.keys())\n",
        "print(key_list)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'cos', 'div', 'infty', 'int', 'log', 'pi', 'sin', 'sqrt', 'tan', 'x', 'y', '-', '(', ')', '+']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrNHRn7V33M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_PATH = '/content/drive/My Drive/extracted_images/extracted_images/'\n",
        "train_files = next(os.walk(TRAIN_PATH))[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PHL95Fqr6yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_img = 0\n",
        "for id_ in train_files:\n",
        "  file_path = TRAIN_PATH + id_ + '/'\n",
        "  img_list = next(os.walk(file_path))[2]\n",
        "  for img_name in img_list:\n",
        "    total_img += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCPMo_VYgsEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54a4b0d8-fe72-4445-e028-c5494a612add"
      },
      "source": [
        "print(total_img)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKIrZKFc6Ih1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "058a41ca-0a08-4437-af46-b16c166ec5ef"
      },
      "source": [
        "X_train = np.zeros((total_img, 45, 45, 1), dtype = np.uint8)\n",
        "Y_train = np.zeros((total_img, 1), dtype = np.int32)\n",
        "\n",
        "print('Getting training data...')\n",
        "sys.stdout.flush()\n",
        "\n",
        "count = 0\n",
        "for n, id_ in tqdm(enumerate(train_files), total = len(train_files)):\n",
        "  label = -1\n",
        "  for i in key_list:\n",
        "    if id_ == i:\n",
        "      label = id_\n",
        "      break\n",
        "  \n",
        "  file_path = TRAIN_PATH + id_ + '/'\n",
        "  img_list = next(os.walk(file_path))[2]\n",
        "  for img_name in img_list:\n",
        "    img_path = file_path + img_name\n",
        "    img = imread(img_path)\n",
        "    img = np.expand_dims(img, 2)\n",
        "    X_train[count] = img\n",
        "    Y_train[count] = sym_to_int_dict[str(label)]\n",
        "    count += 1\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting training data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [02:16<00:00,  5.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL8ZwRYUzso6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = torch.zeros((total_img, 1, 45, 45))\n",
        "label = torch.zeros((total_img, 1))\n",
        "for n in range(total_img):\n",
        "  img_tensor = TF.to_tensor(TF.to_pil_image(X_train[n]))\n",
        "  train[n] = img_tensor\n",
        "\n",
        "  label_tensor = torch.from_numpy(Y_train[n])\n",
        "  label[n] = label_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3lgbfZn9WsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9ec4624c-bceb-470c-a1d5-cc7f42147be7"
      },
      "source": [
        "print(train.shape)\n",
        "print(label.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([54396, 1, 45, 45])\n",
            "torch.Size([54396, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5hDflhitGf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test, label_train, label_test = train_test_split(train, label, test_size = 0.2, random_state = random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1b6Qli9uyPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "148778ff-3677-4c6b-9b19-bd2841537bfe"
      },
      "source": [
        "img = np.array(TF.to_pil_image(train[40000]))\n",
        "plt.imshow(img, cmap = 'gray')\n",
        "plt.show()\n",
        "\n",
        "print(label_train[40000])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLWX74OqcNtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(train, label_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
        "\n",
        "val_dataset = TensorDataset(test, label_test)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGTSwnT3dIJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(dropout, drop_val, in_channels, out_channels, *args, **kwargs):\n",
        "  if dropout:\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, *args, **kwargs),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.Dropout2d(drop_val),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  else:\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, *args, **kwargs),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj2wVukjbu6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class sym_rec(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv_layers = nn.Sequential(\n",
        "        conv_block(False, 0, 1, 32, kernel_size = (5, 5), stride = 1, padding = 2),\n",
        "        conv_block(True, 0.25, 32, 32, kernel_size = (5, 5), stride = 1, padding = 2),\n",
        "        nn.MaxPool2d(kernel_size = (2, 2)),\n",
        "        conv_block(False, 0, 32, 64, kernel_size = (5, 5), stride = 1, padding = 2),\n",
        "        conv_block(True, 0.25, 64, 64, kernel_size = (5, 5), stride = 1, padding = 2),\n",
        "        nn.MaxPool2d(kernel_size = (2, 2), stride = 2),\n",
        "        conv_block(False, 0, 64, 128, kernel_size = (3, 3), stride = 1, padding = 1),\n",
        "        conv_block(True, 0.25, 128, 128, kernel_size = (3, 3), stride = 1, padding = 1),\n",
        "        nn.MaxPool2d(kernel_size = (2, 2), stride = 2)\n",
        "    )\n",
        "\n",
        "    self.lin_layers = nn.Sequential(\n",
        "        nn.Linear(3200, 256),\n",
        "        nn.BatchNorm1d(256),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 25),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.conv_layers(x)\n",
        "    \n",
        "    x = x.view(-1, 3200)\n",
        "\n",
        "    out = self.lin_layers(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56tX3RqQtqTm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "f9d298ad-ce1b-49b9-d06b-831a124c87fb"
      },
      "source": [
        "model = sym_rec()\n",
        "model = model.float()\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(total_params)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sym_rec(\n",
            "  (conv_layers): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Dropout2d(p=0.25, inplace=False)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Dropout2d(p=0.25, inplace=False)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Dropout2d(p=0.25, inplace=False)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (8): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (lin_layers): Sequential(\n",
            "    (0): Linear(in_features=3200, out_features=256, bias=True)\n",
            "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=25, bias=True)\n",
            "    (5): Sigmoid()\n",
            "  )\n",
            ")\n",
            "1228921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PyRzMlbiJY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, patience = 1, verbose = True)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZIV5CPdt_S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(model, epochs, opt, loss_func, train_loader, valid_loader):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        #Going into training mode\n",
        "        model.train()\n",
        "        \n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "       \n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(device)   #Passing the input mini-batch to the GPU\n",
        "            yb = yb.to(device)   #Passing the label mini-batch to the GPU\n",
        "            yb = yb.long()\n",
        "            opt.zero_grad()      #Setting the grads to zero to avoid accumulation of gradients\n",
        "            out = model(xb.float())\n",
        "            loss = loss_func(out, yb.squeeze())    #Squeezing yb so it has dimensions (minibatch_size,)\n",
        "            train_loss += loss\n",
        "            train_pred = torch.argmax(out, dim = 1)\n",
        "            train_pred = train_pred.reshape(train_pred.size()[0], 1) #Setting train_pred to have shape (minibatch_size, 1)\n",
        "            train_acc += (train_pred == yb).float().mean()\n",
        "            \n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        lr_scheduler.step(train_loss/len(train_loader))   #Setting up lr decay  \n",
        "        \n",
        "        model.eval()            #Going into eval mode                            \n",
        "        with torch.no_grad():   #No backprop\n",
        "            valid_loss = 0\n",
        "            valid_acc = 0\n",
        "            \n",
        "            for xb, yb in valid_loader:\n",
        "                xb = xb.to(device)  \n",
        "                yb = yb.to(device)\n",
        "                yb = yb.long()\n",
        "                cv_out = model(xb.float())\n",
        "                valid_loss += loss_func(cv_out, yb.squeeze())\n",
        "                valid_pred = torch.argmax(cv_out, dim = 1)\n",
        "                valid_pred = valid_pred.reshape(valid_pred.size()[0], 1)\n",
        "                valid_acc += (valid_pred == yb).float().mean()\n",
        "        \n",
        "        print(\"Epoch \", epoch, \" Training Loss: \", train_loss/len(train_loader), \"CV Loss: \", valid_loss/len(valid_loader))\n",
        "        print(\"Training Acc: \", train_acc/len(train_loader), \"CV Acc: \", valid_acc/len(valid_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9HXV6aEv8ey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fe81ece-e241-41ae-e63d-480ed2329fb7"
      },
      "source": [
        "fit(model, 150, opt, loss_func, train_loader, val_loader)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0  Training Loss:  tensor(3.7484, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(1.7642, device='cuda:0')\n",
            "Training Acc:  tensor(0.4631, device='cuda:0') CV Acc:  tensor(0.7702, device='cuda:0')\n",
            "Epoch  1  Training Loss:  tensor(2.7556, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(1.0281, device='cuda:0')\n",
            "Training Acc:  tensor(0.5928, device='cuda:0') CV Acc:  tensor(0.8453, device='cuda:0')\n",
            "Epoch  2  Training Loss:  tensor(2.5375, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.8236, device='cuda:0')\n",
            "Training Acc:  tensor(0.6287, device='cuda:0') CV Acc:  tensor(0.8640, device='cuda:0')\n",
            "Epoch  3  Training Loss:  tensor(2.4331, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.7383, device='cuda:0')\n",
            "Training Acc:  tensor(0.6461, device='cuda:0') CV Acc:  tensor(0.8894, device='cuda:0')\n",
            "Epoch  4  Training Loss:  tensor(2.3521, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.6552, device='cuda:0')\n",
            "Training Acc:  tensor(0.6600, device='cuda:0') CV Acc:  tensor(0.8979, device='cuda:0')\n",
            "Epoch  5  Training Loss:  tensor(2.3564, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.4893, device='cuda:0')\n",
            "Training Acc:  tensor(0.6638, device='cuda:0') CV Acc:  tensor(0.9001, device='cuda:0')\n",
            "Epoch  6  Training Loss:  tensor(2.3090, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.4722, device='cuda:0')\n",
            "Training Acc:  tensor(0.6730, device='cuda:0') CV Acc:  tensor(0.9117, device='cuda:0')\n",
            "Epoch  7  Training Loss:  tensor(2.3249, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.7331, device='cuda:0')\n",
            "Training Acc:  tensor(0.6698, device='cuda:0') CV Acc:  tensor(0.8437, device='cuda:0')\n",
            "Epoch  8  Training Loss:  tensor(2.2691, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.3927, device='cuda:0')\n",
            "Training Acc:  tensor(0.6809, device='cuda:0') CV Acc:  tensor(0.9230, device='cuda:0')\n",
            "Epoch  9  Training Loss:  tensor(2.2157, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.5696, device='cuda:0')\n",
            "Training Acc:  tensor(0.6881, device='cuda:0') CV Acc:  tensor(0.8964, device='cuda:0')\n",
            "Epoch  10  Training Loss:  tensor(2.2149, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.4602, device='cuda:0')\n",
            "Training Acc:  tensor(0.6902, device='cuda:0') CV Acc:  tensor(0.9021, device='cuda:0')\n",
            "Epoch  11  Training Loss:  tensor(2.2571, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.6204, device='cuda:0')\n",
            "Training Acc:  tensor(0.6861, device='cuda:0') CV Acc:  tensor(0.8619, device='cuda:0')\n",
            "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch  12  Training Loss:  tensor(2.2379, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.3848, device='cuda:0')\n",
            "Training Acc:  tensor(0.6918, device='cuda:0') CV Acc:  tensor(0.9234, device='cuda:0')\n",
            "Epoch  13  Training Loss:  tensor(2.1656, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2516, device='cuda:0')\n",
            "Training Acc:  tensor(0.7052, device='cuda:0') CV Acc:  tensor(0.9436, device='cuda:0')\n",
            "Epoch  14  Training Loss:  tensor(2.1850, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2466, device='cuda:0')\n",
            "Training Acc:  tensor(0.7047, device='cuda:0') CV Acc:  tensor(0.9438, device='cuda:0')\n",
            "Epoch  15  Training Loss:  tensor(2.1441, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2436, device='cuda:0')\n",
            "Training Acc:  tensor(0.7118, device='cuda:0') CV Acc:  tensor(0.9453, device='cuda:0')\n",
            "Epoch  16  Training Loss:  tensor(2.1529, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2388, device='cuda:0')\n",
            "Training Acc:  tensor(0.7113, device='cuda:0') CV Acc:  tensor(0.9449, device='cuda:0')\n",
            "Epoch  17  Training Loss:  tensor(2.1358, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2347, device='cuda:0')\n",
            "Training Acc:  tensor(0.7146, device='cuda:0') CV Acc:  tensor(0.9448, device='cuda:0')\n",
            "Epoch  18  Training Loss:  tensor(2.1181, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2366, device='cuda:0')\n",
            "Training Acc:  tensor(0.7159, device='cuda:0') CV Acc:  tensor(0.9441, device='cuda:0')\n",
            "Epoch  19  Training Loss:  tensor(2.1593, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2340, device='cuda:0')\n",
            "Training Acc:  tensor(0.7119, device='cuda:0') CV Acc:  tensor(0.9451, device='cuda:0')\n",
            "Epoch    21: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch  20  Training Loss:  tensor(2.1476, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2238, device='cuda:0')\n",
            "Training Acc:  tensor(0.7136, device='cuda:0') CV Acc:  tensor(0.9459, device='cuda:0')\n",
            "Epoch  21  Training Loss:  tensor(2.1426, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2206, device='cuda:0')\n",
            "Training Acc:  tensor(0.7155, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch    23: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch  22  Training Loss:  tensor(2.1238, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2192, device='cuda:0')\n",
            "Training Acc:  tensor(0.7174, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  23  Training Loss:  tensor(2.1391, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2192, device='cuda:0')\n",
            "Training Acc:  tensor(0.7158, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  24  Training Loss:  tensor(2.1152, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2188, device='cuda:0')\n",
            "Training Acc:  tensor(0.7191, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  25  Training Loss:  tensor(2.1306, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2205, device='cuda:0')\n",
            "Training Acc:  tensor(0.7166, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch    27: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch  26  Training Loss:  tensor(2.1354, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2206, device='cuda:0')\n",
            "Training Acc:  tensor(0.7163, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  27  Training Loss:  tensor(2.1372, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2204, device='cuda:0')\n",
            "Training Acc:  tensor(0.7161, device='cuda:0') CV Acc:  tensor(0.9480, device='cuda:0')\n",
            "Epoch    29: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch  28  Training Loss:  tensor(2.1276, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2207, device='cuda:0')\n",
            "Training Acc:  tensor(0.7171, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  29  Training Loss:  tensor(2.1388, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2205, device='cuda:0')\n",
            "Training Acc:  tensor(0.7159, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  30  Training Loss:  tensor(2.1493, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2210, device='cuda:0')\n",
            "Training Acc:  tensor(0.7140, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  31  Training Loss:  tensor(2.1313, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2202, device='cuda:0')\n",
            "Training Acc:  tensor(0.7158, device='cuda:0') CV Acc:  tensor(0.9481, device='cuda:0')\n",
            "Epoch  32  Training Loss:  tensor(2.1034, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2220, device='cuda:0')\n",
            "Training Acc:  tensor(0.7205, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  33  Training Loss:  tensor(2.1319, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2208, device='cuda:0')\n",
            "Training Acc:  tensor(0.7168, device='cuda:0') CV Acc:  tensor(0.9473, device='cuda:0')\n",
            "Epoch  34  Training Loss:  tensor(2.1251, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2194, device='cuda:0')\n",
            "Training Acc:  tensor(0.7179, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  35  Training Loss:  tensor(2.1279, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2204, device='cuda:0')\n",
            "Training Acc:  tensor(0.7181, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  36  Training Loss:  tensor(2.1439, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2221, device='cuda:0')\n",
            "Training Acc:  tensor(0.7147, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  37  Training Loss:  tensor(2.1409, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2190, device='cuda:0')\n",
            "Training Acc:  tensor(0.7152, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  38  Training Loss:  tensor(2.1517, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2222, device='cuda:0')\n",
            "Training Acc:  tensor(0.7150, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  39  Training Loss:  tensor(2.1283, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2193, device='cuda:0')\n",
            "Training Acc:  tensor(0.7172, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  40  Training Loss:  tensor(2.1513, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2186, device='cuda:0')\n",
            "Training Acc:  tensor(0.7148, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  41  Training Loss:  tensor(2.1068, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2215, device='cuda:0')\n",
            "Training Acc:  tensor(0.7204, device='cuda:0') CV Acc:  tensor(0.9479, device='cuda:0')\n",
            "Epoch  42  Training Loss:  tensor(2.1248, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2196, device='cuda:0')\n",
            "Training Acc:  tensor(0.7179, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  43  Training Loss:  tensor(2.1533, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2199, device='cuda:0')\n",
            "Training Acc:  tensor(0.7143, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  44  Training Loss:  tensor(2.1664, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2201, device='cuda:0')\n",
            "Training Acc:  tensor(0.7114, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  45  Training Loss:  tensor(2.1251, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2207, device='cuda:0')\n",
            "Training Acc:  tensor(0.7183, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  46  Training Loss:  tensor(2.1206, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2193, device='cuda:0')\n",
            "Training Acc:  tensor(0.7180, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  47  Training Loss:  tensor(2.1415, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2213, device='cuda:0')\n",
            "Training Acc:  tensor(0.7160, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  48  Training Loss:  tensor(2.1212, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2223, device='cuda:0')\n",
            "Training Acc:  tensor(0.7181, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  49  Training Loss:  tensor(2.1121, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2193, device='cuda:0')\n",
            "Training Acc:  tensor(0.7187, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  50  Training Loss:  tensor(2.1226, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2202, device='cuda:0')\n",
            "Training Acc:  tensor(0.7179, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  51  Training Loss:  tensor(2.1185, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2217, device='cuda:0')\n",
            "Training Acc:  tensor(0.7193, device='cuda:0') CV Acc:  tensor(0.9479, device='cuda:0')\n",
            "Epoch  52  Training Loss:  tensor(2.1455, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2195, device='cuda:0')\n",
            "Training Acc:  tensor(0.7147, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  53  Training Loss:  tensor(2.1252, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2215, device='cuda:0')\n",
            "Training Acc:  tensor(0.7177, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  54  Training Loss:  tensor(2.1398, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2202, device='cuda:0')\n",
            "Training Acc:  tensor(0.7159, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  55  Training Loss:  tensor(2.1316, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2213, device='cuda:0')\n",
            "Training Acc:  tensor(0.7171, device='cuda:0') CV Acc:  tensor(0.9479, device='cuda:0')\n",
            "Epoch  56  Training Loss:  tensor(2.1269, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2196, device='cuda:0')\n",
            "Training Acc:  tensor(0.7163, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  57  Training Loss:  tensor(2.1409, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2204, device='cuda:0')\n",
            "Training Acc:  tensor(0.7159, device='cuda:0') CV Acc:  tensor(0.9479, device='cuda:0')\n",
            "Epoch  58  Training Loss:  tensor(2.1033, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2206, device='cuda:0')\n",
            "Training Acc:  tensor(0.7196, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  59  Training Loss:  tensor(2.1337, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2198, device='cuda:0')\n",
            "Training Acc:  tensor(0.7166, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  60  Training Loss:  tensor(2.1210, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2201, device='cuda:0')\n",
            "Training Acc:  tensor(0.7177, device='cuda:0') CV Acc:  tensor(0.9473, device='cuda:0')\n",
            "Epoch  61  Training Loss:  tensor(2.1318, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2230, device='cuda:0')\n",
            "Training Acc:  tensor(0.7171, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  62  Training Loss:  tensor(2.1257, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2201, device='cuda:0')\n",
            "Training Acc:  tensor(0.7179, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  63  Training Loss:  tensor(2.1290, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2211, device='cuda:0')\n",
            "Training Acc:  tensor(0.7168, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  64  Training Loss:  tensor(2.1122, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2206, device='cuda:0')\n",
            "Training Acc:  tensor(0.7199, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  65  Training Loss:  tensor(2.1202, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2171, device='cuda:0')\n",
            "Training Acc:  tensor(0.7179, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  66  Training Loss:  tensor(2.1119, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2215, device='cuda:0')\n",
            "Training Acc:  tensor(0.7194, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  67  Training Loss:  tensor(2.1582, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2199, device='cuda:0')\n",
            "Training Acc:  tensor(0.7140, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  68  Training Loss:  tensor(2.1162, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2200, device='cuda:0')\n",
            "Training Acc:  tensor(0.7178, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  69  Training Loss:  tensor(2.1103, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2197, device='cuda:0')\n",
            "Training Acc:  tensor(0.7192, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  70  Training Loss:  tensor(2.1548, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2201, device='cuda:0')\n",
            "Training Acc:  tensor(0.7137, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  71  Training Loss:  tensor(2.1231, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2201, device='cuda:0')\n",
            "Training Acc:  tensor(0.7185, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  72  Training Loss:  tensor(2.1274, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2202, device='cuda:0')\n",
            "Training Acc:  tensor(0.7175, device='cuda:0') CV Acc:  tensor(0.9479, device='cuda:0')\n",
            "Epoch  73  Training Loss:  tensor(2.1021, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2203, device='cuda:0')\n",
            "Training Acc:  tensor(0.7206, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  74  Training Loss:  tensor(2.1276, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2200, device='cuda:0')\n",
            "Training Acc:  tensor(0.7176, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  75  Training Loss:  tensor(2.1254, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2199, device='cuda:0')\n",
            "Training Acc:  tensor(0.7174, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  76  Training Loss:  tensor(2.1580, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2210, device='cuda:0')\n",
            "Training Acc:  tensor(0.7134, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  77  Training Loss:  tensor(2.1239, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2225, device='cuda:0')\n",
            "Training Acc:  tensor(0.7179, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  78  Training Loss:  tensor(2.1236, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2213, device='cuda:0')\n",
            "Training Acc:  tensor(0.7172, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  79  Training Loss:  tensor(2.1576, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2209, device='cuda:0')\n",
            "Training Acc:  tensor(0.7139, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  80  Training Loss:  tensor(2.0960, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2209, device='cuda:0')\n",
            "Training Acc:  tensor(0.7212, device='cuda:0') CV Acc:  tensor(0.9479, device='cuda:0')\n",
            "Epoch  81  Training Loss:  tensor(2.1335, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2188, device='cuda:0')\n",
            "Training Acc:  tensor(0.7153, device='cuda:0') CV Acc:  tensor(0.9471, device='cuda:0')\n",
            "Epoch  82  Training Loss:  tensor(2.1158, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2214, device='cuda:0')\n",
            "Training Acc:  tensor(0.7191, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  83  Training Loss:  tensor(2.1515, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2190, device='cuda:0')\n",
            "Training Acc:  tensor(0.7142, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  84  Training Loss:  tensor(2.1138, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2197, device='cuda:0')\n",
            "Training Acc:  tensor(0.7185, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  85  Training Loss:  tensor(2.1501, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2193, device='cuda:0')\n",
            "Training Acc:  tensor(0.7144, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  86  Training Loss:  tensor(2.1247, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2209, device='cuda:0')\n",
            "Training Acc:  tensor(0.7176, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  87  Training Loss:  tensor(2.1393, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2215, device='cuda:0')\n",
            "Training Acc:  tensor(0.7167, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  88  Training Loss:  tensor(2.1209, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2195, device='cuda:0')\n",
            "Training Acc:  tensor(0.7185, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  89  Training Loss:  tensor(2.1645, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2204, device='cuda:0')\n",
            "Training Acc:  tensor(0.7123, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  90  Training Loss:  tensor(2.1141, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2210, device='cuda:0')\n",
            "Training Acc:  tensor(0.7185, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  91  Training Loss:  tensor(2.1245, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2214, device='cuda:0')\n",
            "Training Acc:  tensor(0.7181, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  92  Training Loss:  tensor(2.1735, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2206, device='cuda:0')\n",
            "Training Acc:  tensor(0.7122, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  93  Training Loss:  tensor(2.1460, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2195, device='cuda:0')\n",
            "Training Acc:  tensor(0.7151, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  94  Training Loss:  tensor(2.1472, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2200, device='cuda:0')\n",
            "Training Acc:  tensor(0.7150, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  95  Training Loss:  tensor(2.1744, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2188, device='cuda:0')\n",
            "Training Acc:  tensor(0.7117, device='cuda:0') CV Acc:  tensor(0.9473, device='cuda:0')\n",
            "Epoch  96  Training Loss:  tensor(2.1335, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2207, device='cuda:0')\n",
            "Training Acc:  tensor(0.7175, device='cuda:0') CV Acc:  tensor(0.9479, device='cuda:0')\n",
            "Epoch  97  Training Loss:  tensor(2.1382, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2213, device='cuda:0')\n",
            "Training Acc:  tensor(0.7156, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  98  Training Loss:  tensor(2.1141, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2214, device='cuda:0')\n",
            "Training Acc:  tensor(0.7190, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  99  Training Loss:  tensor(2.1314, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2213, device='cuda:0')\n",
            "Training Acc:  tensor(0.7176, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  100  Training Loss:  tensor(2.1619, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2196, device='cuda:0')\n",
            "Training Acc:  tensor(0.7132, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  101  Training Loss:  tensor(2.1336, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2205, device='cuda:0')\n",
            "Training Acc:  tensor(0.7162, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  102  Training Loss:  tensor(2.1371, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2197, device='cuda:0')\n",
            "Training Acc:  tensor(0.7164, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  103  Training Loss:  tensor(2.1379, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2202, device='cuda:0')\n",
            "Training Acc:  tensor(0.7172, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  104  Training Loss:  tensor(2.1235, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2214, device='cuda:0')\n",
            "Training Acc:  tensor(0.7180, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  105  Training Loss:  tensor(2.0903, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2214, device='cuda:0')\n",
            "Training Acc:  tensor(0.7215, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  106  Training Loss:  tensor(2.1564, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2216, device='cuda:0')\n",
            "Training Acc:  tensor(0.7130, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  107  Training Loss:  tensor(2.1457, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2215, device='cuda:0')\n",
            "Training Acc:  tensor(0.7148, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  108  Training Loss:  tensor(2.1159, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2190, device='cuda:0')\n",
            "Training Acc:  tensor(0.7184, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  109  Training Loss:  tensor(2.1523, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2188, device='cuda:0')\n",
            "Training Acc:  tensor(0.7144, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  110  Training Loss:  tensor(2.0984, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2202, device='cuda:0')\n",
            "Training Acc:  tensor(0.7210, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  111  Training Loss:  tensor(2.1833, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2195, device='cuda:0')\n",
            "Training Acc:  tensor(0.7104, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  112  Training Loss:  tensor(2.1155, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2189, device='cuda:0')\n",
            "Training Acc:  tensor(0.7191, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  113  Training Loss:  tensor(2.1520, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2230, device='cuda:0')\n",
            "Training Acc:  tensor(0.7144, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  114  Training Loss:  tensor(2.1168, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2201, device='cuda:0')\n",
            "Training Acc:  tensor(0.7188, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  115  Training Loss:  tensor(2.1596, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2215, device='cuda:0')\n",
            "Training Acc:  tensor(0.7133, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  116  Training Loss:  tensor(2.1216, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2214, device='cuda:0')\n",
            "Training Acc:  tensor(0.7182, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  117  Training Loss:  tensor(2.1325, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2199, device='cuda:0')\n",
            "Training Acc:  tensor(0.7169, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  118  Training Loss:  tensor(2.1190, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2191, device='cuda:0')\n",
            "Training Acc:  tensor(0.7184, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  119  Training Loss:  tensor(2.1273, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2207, device='cuda:0')\n",
            "Training Acc:  tensor(0.7171, device='cuda:0') CV Acc:  tensor(0.9473, device='cuda:0')\n",
            "Epoch  120  Training Loss:  tensor(2.1218, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2209, device='cuda:0')\n",
            "Training Acc:  tensor(0.7176, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  121  Training Loss:  tensor(2.1305, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2204, device='cuda:0')\n",
            "Training Acc:  tensor(0.7172, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  122  Training Loss:  tensor(2.1474, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2213, device='cuda:0')\n",
            "Training Acc:  tensor(0.7153, device='cuda:0') CV Acc:  tensor(0.9473, device='cuda:0')\n",
            "Epoch  123  Training Loss:  tensor(2.1412, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2210, device='cuda:0')\n",
            "Training Acc:  tensor(0.7163, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  124  Training Loss:  tensor(2.1519, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2210, device='cuda:0')\n",
            "Training Acc:  tensor(0.7141, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  125  Training Loss:  tensor(2.1176, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2201, device='cuda:0')\n",
            "Training Acc:  tensor(0.7177, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  126  Training Loss:  tensor(2.1512, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2200, device='cuda:0')\n",
            "Training Acc:  tensor(0.7147, device='cuda:0') CV Acc:  tensor(0.9473, device='cuda:0')\n",
            "Epoch  127  Training Loss:  tensor(2.1549, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2212, device='cuda:0')\n",
            "Training Acc:  tensor(0.7129, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  128  Training Loss:  tensor(2.1310, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2220, device='cuda:0')\n",
            "Training Acc:  tensor(0.7174, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  129  Training Loss:  tensor(2.1477, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2198, device='cuda:0')\n",
            "Training Acc:  tensor(0.7150, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  130  Training Loss:  tensor(2.1176, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2197, device='cuda:0')\n",
            "Training Acc:  tensor(0.7181, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  131  Training Loss:  tensor(2.1493, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2199, device='cuda:0')\n",
            "Training Acc:  tensor(0.7146, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  132  Training Loss:  tensor(2.1522, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2203, device='cuda:0')\n",
            "Training Acc:  tensor(0.7133, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  133  Training Loss:  tensor(2.1561, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2194, device='cuda:0')\n",
            "Training Acc:  tensor(0.7149, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  134  Training Loss:  tensor(2.1309, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2189, device='cuda:0')\n",
            "Training Acc:  tensor(0.7167, device='cuda:0') CV Acc:  tensor(0.9474, device='cuda:0')\n",
            "Epoch  135  Training Loss:  tensor(2.1269, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2199, device='cuda:0')\n",
            "Training Acc:  tensor(0.7167, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  136  Training Loss:  tensor(2.1371, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2200, device='cuda:0')\n",
            "Training Acc:  tensor(0.7164, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  137  Training Loss:  tensor(2.1225, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2191, device='cuda:0')\n",
            "Training Acc:  tensor(0.7180, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  138  Training Loss:  tensor(2.1376, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2217, device='cuda:0')\n",
            "Training Acc:  tensor(0.7167, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  139  Training Loss:  tensor(2.1159, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2198, device='cuda:0')\n",
            "Training Acc:  tensor(0.7179, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  140  Training Loss:  tensor(2.1156, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2189, device='cuda:0')\n",
            "Training Acc:  tensor(0.7195, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  141  Training Loss:  tensor(2.1350, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2187, device='cuda:0')\n",
            "Training Acc:  tensor(0.7170, device='cuda:0') CV Acc:  tensor(0.9472, device='cuda:0')\n",
            "Epoch  142  Training Loss:  tensor(2.0909, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2219, device='cuda:0')\n",
            "Training Acc:  tensor(0.7217, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  143  Training Loss:  tensor(2.1040, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2213, device='cuda:0')\n",
            "Training Acc:  tensor(0.7200, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n",
            "Epoch  144  Training Loss:  tensor(2.1386, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2195, device='cuda:0')\n",
            "Training Acc:  tensor(0.7161, device='cuda:0') CV Acc:  tensor(0.9475, device='cuda:0')\n",
            "Epoch  145  Training Loss:  tensor(2.1280, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2210, device='cuda:0')\n",
            "Training Acc:  tensor(0.7174, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  146  Training Loss:  tensor(2.1412, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2194, device='cuda:0')\n",
            "Training Acc:  tensor(0.7156, device='cuda:0') CV Acc:  tensor(0.9473, device='cuda:0')\n",
            "Epoch  147  Training Loss:  tensor(2.1610, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2202, device='cuda:0')\n",
            "Training Acc:  tensor(0.7134, device='cuda:0') CV Acc:  tensor(0.9476, device='cuda:0')\n",
            "Epoch  148  Training Loss:  tensor(2.1136, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2208, device='cuda:0')\n",
            "Training Acc:  tensor(0.7196, device='cuda:0') CV Acc:  tensor(0.9478, device='cuda:0')\n",
            "Epoch  149  Training Loss:  tensor(2.1276, device='cuda:0', grad_fn=<DivBackward0>) CV Loss:  tensor(0.2225, device='cuda:0')\n",
            "Training Acc:  tensor(0.7178, device='cuda:0') CV Acc:  tensor(0.9477, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srjUGeoq938P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/sym_rec_mod.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}